{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/header.png\">\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploiting Sentinel-1 SAR time series and artificial neural networks to detect grasslands in the northern Brazilian Amazon\n",
    "\n",
    "[Part 2 - Data preparation]\n",
    "\n",
    "Willian Vieira de Oliveira"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Summary'></a>\n",
    "### SUMMARY\n",
    "\n",
    "1. [**Project Description**](./1_Project_Description.ipynb#About)\n",
    "    1. [Primary objective](./1_Project_Description.ipynb#PrimaryObjetive)\n",
    "    1. [Secondary objectives](./1_Project_Description.ipynb#SecondaryObjetives)\n",
    "    \n",
    "1. [**Study Site**](./1_Project_Description.ipynb#StudySite)\n",
    "\n",
    "1. [**Sentinel-1 Data Description**](./1_Project_Description.ipynb#DataDescription)\n",
    "\n",
    "1. [**Methodology Flowchart**](./1_Project_Description.ipynb#Methodology)\n",
    "    1. [**MLP Architecture**](./1_Project_Description.ipynb#MLP)\n",
    "    1. [**CNN Architecture**](./1_Project_Description.ipynb#CNN)\n",
    "    1. [**LSTM Architecture**](./1_Project_Description.ipynb#LSTM)\n",
    "    \n",
    "1. [**Data preparation**](#Summary)\n",
    "\n",
    "1. [**Data classification**](#Summary)\n",
    "    1. [**Classification of CR data**](./3_Classification_CR.ipynb)\n",
    "    1. [**Classification of NL data**](./3_Classification_NL.ipynb)\n",
    "    1. [**Classification of RGI data**](./3_Classification_RGI.ipynb)\n",
    "    1. [**Classification of VH data**](./3_Classification_VH.ipynb)\n",
    "    1. [**Classification of VV data**](./3_Classification_VV.ipynb)\n",
    "    \n",
    "1. [**Results**](./4_Results_and_Conclusion.ipynb#Results)\n",
    "\n",
    "1. [**Conclusion**](./4_Results_and_Conclusion.ipynb#Conclusion)\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from osgeo import gdal, ogr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Input parameters\n",
    "\n",
    "#### Image data cubes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = ['VV', 'VH', 'CR', 'NL', 'RGI']\n",
    "directories = [\"DATA/VV_Cube.tif\", \"DATA/VH_Cube.tif\", \"DATA/CR_Cube.tif\", \"DATA/NL_Cube.tif\", \"DATA/RGI_Cube.tif\"]\n",
    "\n",
    "dir_output = \"OUTPUT/\"\n",
    "\n",
    "df_columns = ['2017-09-22', '2017-10-04','2017-10-16','2017-10-28','2017-11-09','2017-11-21','2017-12-03','2017-12-15',\n",
    "           '2017-12-27','2018-01-08','2018-01-20','2018-02-01','2018-02-13','2018-02-25','2018-03-09','2018-03-21',\n",
    "           '2018-04-02','2018-04-14','2018-04-26','2018-05-08','2018-05-20','2018-06-01','2018-06-13','2018-06-25',\n",
    "           '2018-07-07','2018-07-19','2018-07-31','2018-08-12','2018-08-24','2018-09-05','2018-09-17']\n",
    "\n",
    "# Would you like to write the dataframes to CSV files and the classificatio products to GeoTIFF files? ['YES', 'NO']\n",
    "#write_files = 'NO'\n",
    "write_files = 'YES'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading the shapefile that contains point samples related to all the three classes analysed in this study\n",
    "\n",
    "**Obs.:** It is important to use a shapefile in the same projection of the raster image used to extract the pixel values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file was read!\n"
     ]
    }
   ],
   "source": [
    "## Shapefiles with point locations of samples related to different classes\n",
    "shp_samples = \"DATA/amostras_500/amostras_500.shp\"\n",
    "\n",
    "try:\n",
    "    samples_points = gpd.read_file(shp_samples, encoding='utf-8')\n",
    "    print(\"The file was read!\")\n",
    "except Exception as e:\n",
    "    print(str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OBJECTID</th>\n",
       "      <th>class</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>POINT (765244.8964999998 9696722.7234)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>POINT (755975.7882000003 9678883.2358)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   OBJECTID  class                                geometry\n",
       "0         1      0  POINT (765244.8964999998 9696722.7234)\n",
       "1         2      0  POINT (755975.7882000003 9678883.2358)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples_points.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identification of the column related to the class identifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [0: First Column, 1: Second, 2...]\n",
    "class_column = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## AUXILIARY FUNCTIONS\n",
    "\n",
    "#### Extract samples from image using point locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ExtractSamples(raster, header_dates, shp, class_column):\n",
    "    #create dataframe\n",
    "    df = pd.DataFrame(columns=header_dates)\n",
    "    df[\"class\"] = None\n",
    "    \n",
    "    df_temp = pd.DataFrame(np.nan, index=range(1), columns=header_dates)\n",
    "    \n",
    "    src_ds = gdal.Open(raster)\n",
    "    gt = src_ds.GetGeoTransform()\n",
    "    \n",
    "    Nbands = src_ds.RasterCount\n",
    "      \n",
    "    ds = ogr.Open(shp)\n",
    "    lyr = ds.GetLayer()\n",
    "    \n",
    "    row = 0\n",
    "    for feat in lyr:\n",
    "        geom = feat.GetGeometryRef()\n",
    "        mx, my = geom.GetX(), geom.GetY() # coord in map units\n",
    "        \n",
    "        # Convert from map to pixel coordinates\n",
    "        # Only works for geotransforms with no rotation\n",
    "        px = int((mx - gt[0]) / gt[1]) # x pixel\n",
    "        py = int((my - gt[3]) / gt[5]) # y pixel\n",
    "        \n",
    "        #df_temp['X'].loc[0] = float(mx)\n",
    "        #df_temp['Y'].loc[0] = float(my)\n",
    "        \n",
    "        #df_temp[\"class\"].loc[0] = feat[class_column]\n",
    "        \n",
    "        for band in range(0, Nbands):\n",
    "            rb = src_ds.GetRasterBand(band+1)\n",
    "            intval = rb.ReadAsArray(px, py, 1, 1)\n",
    "            \n",
    "            df_temp[header_dates[band]].loc[0] = float(intval[0]) #### this is the value of the pixel, forcing it to a float \n",
    "            \n",
    "        \n",
    "        df.loc[row] = df_temp.loc[0]\n",
    "        df[\"class\"].loc[row] = feat[class_column]\n",
    "        row = row + 1\n",
    "        \n",
    "    # Closing files\n",
    "    src_ds = None\n",
    "    ds = None\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extraction of temporal metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ComputeMetrics(df, option):\n",
    "    if (option == \"samples\"):\n",
    "        # Header of the new dataframe\n",
    "        metrics_header = np.array(['Mean', 'Std', 'Sum', 'Min', 'Max', 'Amplitude', 'CoefVariation', 'Class'])\n",
    "        df_classes = df['class'].copy()\n",
    "        df.drop('class', axis=1, inplace=True)\n",
    "    \n",
    "    else: # Extracting metrics for pixels instead of samples\n",
    "        metrics_header = np.array(['Mean', 'Std', 'Sum', 'Min', 'Max', 'Amplitude', 'CoefVariation'])  \n",
    "    \n",
    "    # Dataframe, composed only by the header\n",
    "    df_metrics = pd.DataFrame(columns=metrics_header)\n",
    "    \n",
    "    # Metrics\n",
    "    df_metrics['Mean'] = df.apply(lambda row : row.mean(), axis = 1)\n",
    "    df_metrics['Std'] = df.apply(lambda row : row.std(), axis = 1)\n",
    "    df_metrics['Sum'] = df.apply(lambda row : row.sum(), axis = 1)\n",
    "    df_metrics['Min'] = df.apply(lambda row : row.min(), axis = 1)\n",
    "    df_metrics['Max'] = df.apply(lambda row : row.max(), axis = 1)\n",
    "    df_metrics['Amplitude'] = df.apply(lambda row : row.max()-row.min(), axis = 1)\n",
    "    df_metrics['CoefVariation'] = df.apply(lambda row : row.std()/row.mean(), axis = 1)\n",
    "    \n",
    "    if (option == \"samples\"):\n",
    "        df_metrics['Class'] = df_classes\n",
    "            \n",
    "    return df_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write a dataframe to CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def WriteCSV(df, filename):\n",
    "    try:\n",
    "        df.to_csv(filename, sep=',', index=False, encoding='utf-8-sig') # using 'utf-8-sig' encoding \n",
    "                                                                        #improves efficiency to open it on Excel.\n",
    "        print(\"    The dataframe was written to file!\")\n",
    "    except Exception as e:\n",
    "        print(str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Open an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def openImage(filepath):\n",
    "    data = gdal.Open(filepath)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## DATA PREPARATION FOR CLASSIFICATION\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time series extraction for sample locations (from shapefile, point locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting TS samples from the:  VV  data cube...\n",
      "    The dataframe was written to file!\n",
      "Extracting TS samples from the:  VH  data cube...\n",
      "    The dataframe was written to file!\n",
      "Extracting TS samples from the:  CR  data cube...\n",
      "    The dataframe was written to file!\n",
      "Extracting TS samples from the:  NL  data cube...\n",
      "    The dataframe was written to file!\n",
      "Extracting TS samples from the:  RGI  data cube...\n",
      "    The dataframe was written to file!\n"
     ]
    }
   ],
   "source": [
    "dataframes_samplesTS = []\n",
    "\n",
    "for i, (filename, directory) in enumerate(zip(filenames, directories)):\n",
    "    print(\"Extracting TS samples from the: \", filename, \" data cube...\")\n",
    "    df_samplesTS = ExtractSamples(directory, df_columns, shp_samples, class_column)\n",
    "    df_samplesTS['class'] = df_samplesTS['class'].apply(int) # convert column 'class' from float to int\n",
    "    \n",
    "    # Writing the dataframe to CSV file\n",
    "    if (write_files == 'YES'):\n",
    "        WriteCSV(df_samplesTS, dir_output+'TimeSeries_AllSamples_'+filename+'.csv')\n",
    "    \n",
    "    dataframes_samplesTS.append(df_samplesTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Example: Dataframe obtained for the VH data cube:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2017-09-22</th>\n",
       "      <th>2017-10-04</th>\n",
       "      <th>2017-10-16</th>\n",
       "      <th>2017-10-28</th>\n",
       "      <th>2017-11-09</th>\n",
       "      <th>2017-11-21</th>\n",
       "      <th>2017-12-03</th>\n",
       "      <th>2017-12-15</th>\n",
       "      <th>2017-12-27</th>\n",
       "      <th>2018-01-08</th>\n",
       "      <th>...</th>\n",
       "      <th>2018-06-13</th>\n",
       "      <th>2018-06-25</th>\n",
       "      <th>2018-07-07</th>\n",
       "      <th>2018-07-19</th>\n",
       "      <th>2018-07-31</th>\n",
       "      <th>2018-08-12</th>\n",
       "      <th>2018-08-24</th>\n",
       "      <th>2018-09-05</th>\n",
       "      <th>2018-09-17</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.046227</td>\n",
       "      <td>0.052834</td>\n",
       "      <td>0.052655</td>\n",
       "      <td>0.044659</td>\n",
       "      <td>0.045854</td>\n",
       "      <td>0.048045</td>\n",
       "      <td>0.048873</td>\n",
       "      <td>0.052265</td>\n",
       "      <td>0.067018</td>\n",
       "      <td>0.044270</td>\n",
       "      <td>...</td>\n",
       "      <td>0.057443</td>\n",
       "      <td>0.052766</td>\n",
       "      <td>0.048808</td>\n",
       "      <td>0.055010</td>\n",
       "      <td>0.055540</td>\n",
       "      <td>0.053429</td>\n",
       "      <td>0.053200</td>\n",
       "      <td>0.042548</td>\n",
       "      <td>0.049838</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.057436</td>\n",
       "      <td>0.069680</td>\n",
       "      <td>0.061249</td>\n",
       "      <td>0.056792</td>\n",
       "      <td>0.062407</td>\n",
       "      <td>0.056256</td>\n",
       "      <td>0.052711</td>\n",
       "      <td>0.088279</td>\n",
       "      <td>0.089773</td>\n",
       "      <td>0.077882</td>\n",
       "      <td>...</td>\n",
       "      <td>0.068463</td>\n",
       "      <td>0.075454</td>\n",
       "      <td>0.076519</td>\n",
       "      <td>0.087927</td>\n",
       "      <td>0.072986</td>\n",
       "      <td>0.063441</td>\n",
       "      <td>0.059012</td>\n",
       "      <td>0.065404</td>\n",
       "      <td>0.063618</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.054750</td>\n",
       "      <td>0.044581</td>\n",
       "      <td>0.052402</td>\n",
       "      <td>0.049010</td>\n",
       "      <td>0.052049</td>\n",
       "      <td>0.048011</td>\n",
       "      <td>0.053907</td>\n",
       "      <td>0.067100</td>\n",
       "      <td>0.075462</td>\n",
       "      <td>0.071251</td>\n",
       "      <td>...</td>\n",
       "      <td>0.081516</td>\n",
       "      <td>0.063253</td>\n",
       "      <td>0.063312</td>\n",
       "      <td>0.062837</td>\n",
       "      <td>0.063550</td>\n",
       "      <td>0.049705</td>\n",
       "      <td>0.054140</td>\n",
       "      <td>0.055232</td>\n",
       "      <td>0.056488</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.036321</td>\n",
       "      <td>0.033173</td>\n",
       "      <td>0.029707</td>\n",
       "      <td>0.029013</td>\n",
       "      <td>0.032870</td>\n",
       "      <td>0.033574</td>\n",
       "      <td>0.030071</td>\n",
       "      <td>0.038529</td>\n",
       "      <td>0.049874</td>\n",
       "      <td>0.039385</td>\n",
       "      <td>...</td>\n",
       "      <td>0.045296</td>\n",
       "      <td>0.044558</td>\n",
       "      <td>0.039028</td>\n",
       "      <td>0.043760</td>\n",
       "      <td>0.044582</td>\n",
       "      <td>0.037811</td>\n",
       "      <td>0.035878</td>\n",
       "      <td>0.031677</td>\n",
       "      <td>0.036693</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.034539</td>\n",
       "      <td>0.036610</td>\n",
       "      <td>0.037197</td>\n",
       "      <td>0.043403</td>\n",
       "      <td>0.039930</td>\n",
       "      <td>0.034697</td>\n",
       "      <td>0.034381</td>\n",
       "      <td>0.049837</td>\n",
       "      <td>0.055737</td>\n",
       "      <td>0.046845</td>\n",
       "      <td>...</td>\n",
       "      <td>0.053660</td>\n",
       "      <td>0.052796</td>\n",
       "      <td>0.046458</td>\n",
       "      <td>0.046275</td>\n",
       "      <td>0.053157</td>\n",
       "      <td>0.047727</td>\n",
       "      <td>0.042873</td>\n",
       "      <td>0.054173</td>\n",
       "      <td>0.046401</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   2017-09-22  2017-10-04  2017-10-16  2017-10-28  2017-11-09  2017-11-21  \\\n",
       "0    0.046227    0.052834    0.052655    0.044659    0.045854    0.048045   \n",
       "1    0.057436    0.069680    0.061249    0.056792    0.062407    0.056256   \n",
       "2    0.054750    0.044581    0.052402    0.049010    0.052049    0.048011   \n",
       "3    0.036321    0.033173    0.029707    0.029013    0.032870    0.033574   \n",
       "4    0.034539    0.036610    0.037197    0.043403    0.039930    0.034697   \n",
       "\n",
       "   2017-12-03  2017-12-15  2017-12-27  2018-01-08  ...  2018-06-13  \\\n",
       "0    0.048873    0.052265    0.067018    0.044270  ...    0.057443   \n",
       "1    0.052711    0.088279    0.089773    0.077882  ...    0.068463   \n",
       "2    0.053907    0.067100    0.075462    0.071251  ...    0.081516   \n",
       "3    0.030071    0.038529    0.049874    0.039385  ...    0.045296   \n",
       "4    0.034381    0.049837    0.055737    0.046845  ...    0.053660   \n",
       "\n",
       "   2018-06-25  2018-07-07  2018-07-19  2018-07-31  2018-08-12  2018-08-24  \\\n",
       "0    0.052766    0.048808    0.055010    0.055540    0.053429    0.053200   \n",
       "1    0.075454    0.076519    0.087927    0.072986    0.063441    0.059012   \n",
       "2    0.063253    0.063312    0.062837    0.063550    0.049705    0.054140   \n",
       "3    0.044558    0.039028    0.043760    0.044582    0.037811    0.035878   \n",
       "4    0.052796    0.046458    0.046275    0.053157    0.047727    0.042873   \n",
       "\n",
       "   2018-09-05  2018-09-17  class  \n",
       "0    0.042548    0.049838      0  \n",
       "1    0.065404    0.063618      0  \n",
       "2    0.055232    0.056488      0  \n",
       "3    0.031677    0.036693      0  \n",
       "4    0.054173    0.046401      0  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_samplesTS_VH = dataframes_samplesTS[1]\n",
    "df_samplesTS_VH.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraction of temporal metrics regarding the time series of each sample location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting temporal metrics from the:  VV  dataframe...\n",
      "    The dataframe was written to file!\n",
      "Extracting temporal metrics from the:  VH  dataframe...\n",
      "    The dataframe was written to file!\n",
      "Extracting temporal metrics from the:  CR  dataframe...\n",
      "    The dataframe was written to file!\n",
      "Extracting temporal metrics from the:  NL  dataframe...\n",
      "    The dataframe was written to file!\n",
      "Extracting temporal metrics from the:  RGI  dataframe...\n",
      "    The dataframe was written to file!\n"
     ]
    }
   ],
   "source": [
    "dataframes_metrics_samples = []\n",
    "\n",
    "for i, (filename, df_samplesTS) in enumerate(zip(filenames, dataframes_samplesTS)):\n",
    "    print(\"Extracting temporal metrics from the: \", filename, \" dataframe...\")\n",
    "    df_metrics_samples = ComputeMetrics(df_samplesTS.copy(), 'samples')\n",
    "    \n",
    "    # Writing the dataframe to CSV file\n",
    "    if (write_files == 'YES'):\n",
    "        WriteCSV(df_metrics_samples, dir_output+'Metrics_AllSamples_'+filename+'.csv')\n",
    "    \n",
    "    dataframes_metrics_samples.append(df_metrics_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Example: Metrics extracted from the VH data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Std</th>\n",
       "      <th>Sum</th>\n",
       "      <th>Min</th>\n",
       "      <th>Max</th>\n",
       "      <th>Amplitude</th>\n",
       "      <th>CoefVariation</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.052776</td>\n",
       "      <td>0.005973</td>\n",
       "      <td>1.636049</td>\n",
       "      <td>0.041501</td>\n",
       "      <td>0.067018</td>\n",
       "      <td>0.025516</td>\n",
       "      <td>0.113180</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.072890</td>\n",
       "      <td>0.010835</td>\n",
       "      <td>2.259599</td>\n",
       "      <td>0.052711</td>\n",
       "      <td>0.090519</td>\n",
       "      <td>0.037808</td>\n",
       "      <td>0.148650</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.061596</td>\n",
       "      <td>0.009167</td>\n",
       "      <td>1.909474</td>\n",
       "      <td>0.044581</td>\n",
       "      <td>0.081516</td>\n",
       "      <td>0.036935</td>\n",
       "      <td>0.148825</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.039385</td>\n",
       "      <td>0.006330</td>\n",
       "      <td>1.220950</td>\n",
       "      <td>0.029013</td>\n",
       "      <td>0.051529</td>\n",
       "      <td>0.022516</td>\n",
       "      <td>0.160728</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.047505</td>\n",
       "      <td>0.007001</td>\n",
       "      <td>1.472654</td>\n",
       "      <td>0.034381</td>\n",
       "      <td>0.059871</td>\n",
       "      <td>0.025491</td>\n",
       "      <td>0.147364</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Mean       Std       Sum       Min       Max  Amplitude  CoefVariation  \\\n",
       "0  0.052776  0.005973  1.636049  0.041501  0.067018   0.025516       0.113180   \n",
       "1  0.072890  0.010835  2.259599  0.052711  0.090519   0.037808       0.148650   \n",
       "2  0.061596  0.009167  1.909474  0.044581  0.081516   0.036935       0.148825   \n",
       "3  0.039385  0.006330  1.220950  0.029013  0.051529   0.022516       0.160728   \n",
       "4  0.047505  0.007001  1.472654  0.034381  0.059871   0.025491       0.147364   \n",
       "\n",
       "   Class  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_metrics_samples = dataframes_metrics_samples[1]\n",
    "df_metrics_samples.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Time series extraction for all pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting the TS for all pixels of the:  VV  data cube...\n",
      "    The dataframe was written to file!\n",
      "Extracting the TS for all pixels of the:  VH  data cube...\n",
      "    The dataframe was written to file!\n",
      "Extracting the TS for all pixels of the:  CR  data cube...\n",
      "    The dataframe was written to file!\n",
      "Extracting the TS for all pixels of the:  NL  data cube...\n",
      "    The dataframe was written to file!\n",
      "Extracting the TS for all pixels of the:  RGI  data cube...\n",
      "    The dataframe was written to file!\n"
     ]
    }
   ],
   "source": [
    "dataframes_TimeSeries_AllPixels = []\n",
    "\n",
    "for i, (filename, directory) in enumerate(zip(filenames, directories)):\n",
    "    print(\"Extracting the TS for all pixels of the: \", filename, \" data cube...\")\n",
    "\n",
    "    datacube = openImage(directory)\n",
    "\n",
    "    Nrows = datacube.RasterYSize - 6 # We do not consider border pixels. We removed both the first and the last three rows.\n",
    "    Ncols = datacube.RasterXSize - 6 # We do not consider border pixels. We removed both the first and the last three columns.\n",
    "    Nbands = datacube.RasterCount\n",
    "\n",
    "    arr = datacube.ReadAsArray(3, 3, Ncols, Nrows) # xoff, yoff, xcount, ycount\n",
    "    datacube = None\n",
    "    \n",
    "    df_list = []\n",
    "    for band in range(0, Nbands):\n",
    "        array = arr[band].flatten()\n",
    "        df = pd.DataFrame(array, columns=[df_columns[band]])\n",
    "        df_list.append(df)\n",
    "\n",
    "    df_datacube = pd.concat(df_list, axis=1)\n",
    "\n",
    "    # Writing the dataframe to CSV file\n",
    "    if (write_files == 'YES'):\n",
    "        WriteCSV(df_datacube, dir_output+'TimeSeries_AllPixels_'+filename+'.csv')\n",
    "        \n",
    "    dataframes_TimeSeries_AllPixels.append(df_datacube)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Example: Dataframe obtained for the VH data cube:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2017-09-22</th>\n",
       "      <th>2017-10-04</th>\n",
       "      <th>2017-10-16</th>\n",
       "      <th>2017-10-28</th>\n",
       "      <th>2017-11-09</th>\n",
       "      <th>2017-11-21</th>\n",
       "      <th>2017-12-03</th>\n",
       "      <th>2017-12-15</th>\n",
       "      <th>2017-12-27</th>\n",
       "      <th>2018-01-08</th>\n",
       "      <th>...</th>\n",
       "      <th>2018-06-01</th>\n",
       "      <th>2018-06-13</th>\n",
       "      <th>2018-06-25</th>\n",
       "      <th>2018-07-07</th>\n",
       "      <th>2018-07-19</th>\n",
       "      <th>2018-07-31</th>\n",
       "      <th>2018-08-12</th>\n",
       "      <th>2018-08-24</th>\n",
       "      <th>2018-09-05</th>\n",
       "      <th>2018-09-17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.030140</td>\n",
       "      <td>0.035049</td>\n",
       "      <td>0.026826</td>\n",
       "      <td>0.037771</td>\n",
       "      <td>0.032626</td>\n",
       "      <td>0.028671</td>\n",
       "      <td>0.028586</td>\n",
       "      <td>0.035451</td>\n",
       "      <td>0.043515</td>\n",
       "      <td>0.044464</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038554</td>\n",
       "      <td>0.033150</td>\n",
       "      <td>0.029756</td>\n",
       "      <td>0.033361</td>\n",
       "      <td>0.039310</td>\n",
       "      <td>0.039912</td>\n",
       "      <td>0.031309</td>\n",
       "      <td>0.038160</td>\n",
       "      <td>0.030636</td>\n",
       "      <td>0.035158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.030385</td>\n",
       "      <td>0.033345</td>\n",
       "      <td>0.027814</td>\n",
       "      <td>0.036575</td>\n",
       "      <td>0.032115</td>\n",
       "      <td>0.029239</td>\n",
       "      <td>0.028343</td>\n",
       "      <td>0.037187</td>\n",
       "      <td>0.043729</td>\n",
       "      <td>0.042603</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038298</td>\n",
       "      <td>0.032843</td>\n",
       "      <td>0.029729</td>\n",
       "      <td>0.034149</td>\n",
       "      <td>0.038422</td>\n",
       "      <td>0.037959</td>\n",
       "      <td>0.030161</td>\n",
       "      <td>0.038267</td>\n",
       "      <td>0.030045</td>\n",
       "      <td>0.034407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.026909</td>\n",
       "      <td>0.029020</td>\n",
       "      <td>0.024550</td>\n",
       "      <td>0.030759</td>\n",
       "      <td>0.028446</td>\n",
       "      <td>0.025149</td>\n",
       "      <td>0.025230</td>\n",
       "      <td>0.032081</td>\n",
       "      <td>0.038999</td>\n",
       "      <td>0.036744</td>\n",
       "      <td>...</td>\n",
       "      <td>0.034003</td>\n",
       "      <td>0.029203</td>\n",
       "      <td>0.028400</td>\n",
       "      <td>0.031042</td>\n",
       "      <td>0.033451</td>\n",
       "      <td>0.032695</td>\n",
       "      <td>0.025740</td>\n",
       "      <td>0.033955</td>\n",
       "      <td>0.026470</td>\n",
       "      <td>0.029883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.037398</td>\n",
       "      <td>0.040440</td>\n",
       "      <td>0.034533</td>\n",
       "      <td>0.040932</td>\n",
       "      <td>0.038193</td>\n",
       "      <td>0.034530</td>\n",
       "      <td>0.032443</td>\n",
       "      <td>0.046084</td>\n",
       "      <td>0.052855</td>\n",
       "      <td>0.051553</td>\n",
       "      <td>...</td>\n",
       "      <td>0.047204</td>\n",
       "      <td>0.041964</td>\n",
       "      <td>0.041130</td>\n",
       "      <td>0.048807</td>\n",
       "      <td>0.047363</td>\n",
       "      <td>0.044682</td>\n",
       "      <td>0.036132</td>\n",
       "      <td>0.049332</td>\n",
       "      <td>0.038773</td>\n",
       "      <td>0.042218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.041544</td>\n",
       "      <td>0.043606</td>\n",
       "      <td>0.039519</td>\n",
       "      <td>0.042680</td>\n",
       "      <td>0.042706</td>\n",
       "      <td>0.037016</td>\n",
       "      <td>0.033596</td>\n",
       "      <td>0.049529</td>\n",
       "      <td>0.057144</td>\n",
       "      <td>0.053213</td>\n",
       "      <td>...</td>\n",
       "      <td>0.052151</td>\n",
       "      <td>0.047348</td>\n",
       "      <td>0.044832</td>\n",
       "      <td>0.052455</td>\n",
       "      <td>0.051900</td>\n",
       "      <td>0.048358</td>\n",
       "      <td>0.040474</td>\n",
       "      <td>0.050013</td>\n",
       "      <td>0.039172</td>\n",
       "      <td>0.046000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   2017-09-22  2017-10-04  2017-10-16  2017-10-28  2017-11-09  2017-11-21  \\\n",
       "0    0.030140    0.035049    0.026826    0.037771    0.032626    0.028671   \n",
       "1    0.030385    0.033345    0.027814    0.036575    0.032115    0.029239   \n",
       "2    0.026909    0.029020    0.024550    0.030759    0.028446    0.025149   \n",
       "3    0.037398    0.040440    0.034533    0.040932    0.038193    0.034530   \n",
       "4    0.041544    0.043606    0.039519    0.042680    0.042706    0.037016   \n",
       "\n",
       "   2017-12-03  2017-12-15  2017-12-27  2018-01-08  ...  2018-06-01  \\\n",
       "0    0.028586    0.035451    0.043515    0.044464  ...    0.038554   \n",
       "1    0.028343    0.037187    0.043729    0.042603  ...    0.038298   \n",
       "2    0.025230    0.032081    0.038999    0.036744  ...    0.034003   \n",
       "3    0.032443    0.046084    0.052855    0.051553  ...    0.047204   \n",
       "4    0.033596    0.049529    0.057144    0.053213  ...    0.052151   \n",
       "\n",
       "   2018-06-13  2018-06-25  2018-07-07  2018-07-19  2018-07-31  2018-08-12  \\\n",
       "0    0.033150    0.029756    0.033361    0.039310    0.039912    0.031309   \n",
       "1    0.032843    0.029729    0.034149    0.038422    0.037959    0.030161   \n",
       "2    0.029203    0.028400    0.031042    0.033451    0.032695    0.025740   \n",
       "3    0.041964    0.041130    0.048807    0.047363    0.044682    0.036132   \n",
       "4    0.047348    0.044832    0.052455    0.051900    0.048358    0.040474   \n",
       "\n",
       "   2018-08-24  2018-09-05  2018-09-17  \n",
       "0    0.038160    0.030636    0.035158  \n",
       "1    0.038267    0.030045    0.034407  \n",
       "2    0.033955    0.026470    0.029883  \n",
       "3    0.049332    0.038773    0.042218  \n",
       "4    0.050013    0.039172    0.046000  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_datacube_VH = dataframes_TimeSeries_AllPixels[1]\n",
    "df_datacube_VH.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraction of temporal metrics for all pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting temporal metrics from the:  VV  dataframe...\n",
      "    The dataframe was written to file!\n",
      "Extracting temporal metrics from the:  VH  dataframe...\n",
      "    The dataframe was written to file!\n",
      "Extracting temporal metrics from the:  CR  dataframe...\n",
      "    The dataframe was written to file!\n",
      "Extracting temporal metrics from the:  NL  dataframe...\n",
      "    The dataframe was written to file!\n",
      "Extracting temporal metrics from the:  RGI  dataframe...\n",
      "    The dataframe was written to file!\n"
     ]
    }
   ],
   "source": [
    "dataframes_metrics_pixels = []\n",
    "\n",
    "for i, (filename, df_datacube) in enumerate(zip(filenames, dataframes_TimeSeries_AllPixels)):\n",
    "    print(\"Extracting temporal metrics from the: \", filename, \" dataframe...\")\n",
    "\n",
    "    df_metrics_pixels = ComputeMetrics(df_datacube.copy(), 'pixels')\n",
    "    \n",
    "    # Writing the dataframe to CSV file\n",
    "    if (write_files == 'YES'):\n",
    "        WriteCSV(df_metrics_pixels, dir_output+'Metrics_AllPixels_'+filename+'.csv')\n",
    "    \n",
    "    dataframes_metrics_pixels.append(df_metrics_pixels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Example: Metrics extracted from the VH data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Std</th>\n",
       "      <th>Sum</th>\n",
       "      <th>Min</th>\n",
       "      <th>Max</th>\n",
       "      <th>Amplitude</th>\n",
       "      <th>CoefVariation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.035449</td>\n",
       "      <td>0.004395</td>\n",
       "      <td>1.098929</td>\n",
       "      <td>0.026826</td>\n",
       "      <td>0.044464</td>\n",
       "      <td>0.017639</td>\n",
       "      <td>0.123975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.035027</td>\n",
       "      <td>0.004136</td>\n",
       "      <td>1.085838</td>\n",
       "      <td>0.027814</td>\n",
       "      <td>0.043729</td>\n",
       "      <td>0.015914</td>\n",
       "      <td>0.118093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.030636</td>\n",
       "      <td>0.003566</td>\n",
       "      <td>0.949714</td>\n",
       "      <td>0.024550</td>\n",
       "      <td>0.038999</td>\n",
       "      <td>0.014448</td>\n",
       "      <td>0.116413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.042832</td>\n",
       "      <td>0.005302</td>\n",
       "      <td>1.327800</td>\n",
       "      <td>0.032443</td>\n",
       "      <td>0.052855</td>\n",
       "      <td>0.020412</td>\n",
       "      <td>0.123796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.045681</td>\n",
       "      <td>0.005602</td>\n",
       "      <td>1.416098</td>\n",
       "      <td>0.033596</td>\n",
       "      <td>0.057144</td>\n",
       "      <td>0.023548</td>\n",
       "      <td>0.122624</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Mean       Std       Sum       Min       Max  Amplitude  CoefVariation\n",
       "0  0.035449  0.004395  1.098929  0.026826  0.044464   0.017639       0.123975\n",
       "1  0.035027  0.004136  1.085838  0.027814  0.043729   0.015914       0.118093\n",
       "2  0.030636  0.003566  0.949714  0.024550  0.038999   0.014448       0.116413\n",
       "3  0.042832  0.005302  1.327800  0.032443  0.052855   0.020412       0.123796\n",
       "4  0.045681  0.005602  1.416098  0.033596  0.057144   0.023548       0.122624"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_metrics_pixels = dataframes_metrics_pixels[1]\n",
    "df_metrics_pixels.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
